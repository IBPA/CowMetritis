[DEFAULT]

# do over-sampling using SMOTE
SMOTE = True

# what classifier are we using
#     DummyClassifier
#     DecisionTreeClassifier
#     GaussianNB
#     MultinomialNB
#     CategoricalNB
#     SVC
#     AdaBoostClassifier
#     RandomForestClassifier
#     MLPClassifier
classifier = CategoricalNB

[DecisionTreeClassifier_GridSearch]
criterion = gini, entropy
splitter = best, random
max_depth_start = 1
max_depth_end = 50
max_depth_increment = 2
min_samples_split_start = 2
min_samples_split_end = 11
min_samples_split_increment = 2
min_samples_leaf_start = 1
min_samples_leaf_end = 10
min_samples_leaf_increment = 2

[DecisionTreeClassifier_Best]
criterion = gini
splitter = random
max_depth = 9
min_samples_split = 6
min_samples_leaf = 3

[AdaBoostClassifier_GridSearch]
n_estimators_start = 25
n_estimators_end = 501
n_estimators_increment = 25
learning_rate_start = 0.1
learning_rate_end = 2.1
learning_rate_increment = 0.2
algorithm = SAMME, SAMME.R

[AdaBoostClassifier_Best]
n_estimators = 425
learning_rate = 0.7000000000000001
algorithm = SAMME

[RandomForestClassifier_GridSearch]
n_estimators_start = 50
n_estimators_end = 301
n_estimators_increment = 25
criterion = gini, entropy
min_samples_split_start = 2
min_samples_split_end = 11
min_samples_split_increment = 2
min_samples_leaf_start = 1
min_samples_leaf_end = 10
min_samples_leaf_increment = 2

[RandomForestClassifier_Best]
n_estimators = 125
criterion = entropy
min_samples_split = 6
min_samples_leaf = 1

[MLPClassifier_GridSearch]
num_hidden_layers_start = 1
num_hidden_layers_end = 6
num_hidden_layers_increment = 1
num_hidden_nodes_start = 10
num_hidden_nodes_end = 101
num_hidden_nodes_increment = 10
alpha_start = 0.0001
alpha_end = 0.001
alpha_increment = 0.0003
batch_size_start = 20
batch_size_end = 201
batch_size_increment = 20
max_iter_start = 2500
max_iter_end = 2501
max_iter_increment = 1

[MLPClassifier_Best]
hidden_layer_sizes = (10, 10, 10, 10)
alpha = 0.0007
batch_size = 180
max_iter = 2500
