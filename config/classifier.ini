[DEFAULT]

# what classifier are we using
#     DummyClassifier
#     DecisionTreeClassifier
#     GaussianNB
#     MultinomialNB
#     CategoricalNB
#     SVC
#     AdaBoostClassifier
#     RandomForestClassifier
#     MLPClassifier
classifier = CategoricalNB

[DecisionTreeClassifier_GridSearch]
criterion = gini, entropy
splitter = best, random
max_depth_start = 1
max_depth_end = 50
max_depth_increment = 1
min_samples_split_start = 2
min_samples_split_end = 100
min_samples_split_increment = 2
min_samples_leaf_start = 1
min_samples_leaf_end = 100
min_samples_leaf_increment = 2

[DecisionTreeClassifier_Best]
criterion = gini
splitter = random
max_depth = 48
min_samples_split = 80
min_samples_leaf = 11

[AdaBoostClassifier_GridSearch]
n_estimators_start = 50
n_estimators_end = 500
n_estimators_increment = 10
learning_rate_start = 0.1
learning_rate_end = 2.0
learning_rate_increment = 0.1
algorithm = SAMME, SAMME.R

[AdaBoostClassifier_Best]
n_estimators = 70
learning_rate = 0.1
algorithm = SAMME

[RandomForestClassifier_GridSearch]
n_estimators_start = 50
n_estimators_end = 300
n_estimators_increment = 10
criterion = gini, entropy
min_samples_split_start = 2
min_samples_split_end = 50
min_samples_split_increment = 5
min_samples_leaf_start = 1
min_samples_leaf_end = 50
min_samples_leaf_increment = 5
ccp_alpha_start = 0.0
ccp_alpha_end = 0.5
ccp_alpha_increment = 0.1

[RandomForestClassifier_Best]
n_estimators = 70
criterion = entropy
min_samples_split = 17
min_samples_leaf = 16
ccp_alpha = 0.0

[MLPClassifier_GridSearch]
num_hidden_layers_start = 1
num_hidden_layers_end = 6
num_hidden_layers_increment = 1
num_hidden_nodes_start = 10
num_hidden_nodes_end = 110
num_hidden_nodes_increment = 10
alpha_start = 0.0001
alpha_end = 0.001
alpha_increment = 0.0003
batch_size_start = 50
batch_size_end = 201
batch_size_increment = 10
max_iter_start = 2500
max_iter_end = 2501
max_iter_increment = 1

[MLPClassifier_Best]
hidden_layer_sizes = (10, 10, 10, 10)
alpha = 0.0007
batch_size = 50
max_iter = 2000
